{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoria de Machine Learning: Predicción de Clasificación\n",
    "\n",
    "## 1.Resumen Ejecutivo\n",
    "\n",
    "El objetivo es evaluar varios modelos de ML, para ver cual es el que mejor predice si un préstamo será pagado o impagado, teniendo en cuenta unas serie de características del usuario-cliente.\n",
    "\n",
    "## 2.Definición del Problema\n",
    "\n",
    "- **2.1Descripción del Problema:** Predecir de antemano(antes de hacer la inversión), o sea antes de conceder el préstamo, si será pagado o impagado.\n",
    "\n",
    "- **2.2Importancia:** Rentabilizar los recursos empleados en conceder financiación a los clientes y que estos recursos no sean generadores de pérdidas, al prestarse a clientes con probabilidad de impago.\n",
    "\n",
    "## 3.Exploración de Datos\n",
    "\n",
    "- **3.1.Origen de los Datos:** El dataset que he utilizado para este estudio, esta en el siguiente link, https://www.kaggle.com/datasets/jeandedieunyandwi/lending-club-dataset/data, tiene 396.030 instancias, y 27 características.\n",
    "\n",
    "- **3.2.Análisis Exploratorio de Datos (EDA):** Los detalles correspondientes a este apartado se encuentran en el siguiente enlace [EDA](../notebooks/002_LimpiezaEDA.ipynb)\n",
    "\n",
    "## 4.Preprocesamiento de Datos\n",
    "\n",
    "- **4.1.Limpieza de Datos:** Los detalles correspondientes a este apartado se encuentran en el siguiente enlace [LIMPIEZA](../notebooks/002_LimpiezaEDA.ipynb)\n",
    "\n",
    "- **4.2.Transformación de Características:** Los detalles correspondientes a este apartado se encuentran en el siguiente enlace [TRANSFORMACION](../notebooks/002_LimpiezaEDA.ipynb).\n",
    "\n",
    "## 5.Selección y Entrenamiento del Modelo\n",
    "\n",
    "- **Elección del Modelo:** Se toma como modelo GBC(Gradient Boosting Classifier), al ser el que mejor se comporta en la capacidaad de distinguir entre clases positivas y negativas, teniendo un ROC_AUC score de 0.635.\n",
    "- **Configuración del Modelo:** El proceso de búsqueda de parámetros óptimos (GridSearchCV) puede haber contribuido a mejorar el rendimiento del GBC. Los parámetros óptimos encontrados durante la búsqueda, como {'learning_rate': 0.1, 'max_depth': 2, 'max_features': 3, 'n_estimators': 150}, sugieren una configuración que maximiza el área bajo la curva ROC.\n",
    "- **Entrenamiento del Modelo:** El modelo Gradient Boosting Classifier (GBC) fue entrenado utilizando los siguientes parámetros óptimos:\n",
    "\n",
    "learning_rate: 0.1\n",
    "max_depth: 2\n",
    "max_features: 3\n",
    "n_estimators: 150\n",
    "\n",
    "El conjunto de entrenamiento se utilizó para ajustar el modelo, donde se aplicó la técnica de boosting para mejorar iterativamente la capacidad predictiva del conjunto mediante la construcción de árboles débiles. El modelo resultante es una combinación ponderada de estos árboles, optimizada para maximizar el área bajo la curva ROC (ROC AUC Score).\n",
    "\n",
    "## 6.Evaluación del Modelo\n",
    "\n",
    "- **6.1Métricas de Evaluación y resultados:**\n",
    "\n",
    "Durante el entrenamiento, se calcularon diversas métricas para evaluar el rendimiento del modelo:\n",
    "\n",
    "Accuracy: 0.635 (63.5% de predicciones correctas).\n",
    "\n",
    "Precision: 0.635 (63.5% de verdaderos positivos entre los positivos predichos).\n",
    "\n",
    "Recall: 0.643 (64.3% de positivos reales identificados).\n",
    "\n",
    "F1 Score: 0.639 (63.9% de equilibrio entre precision y recall).\n",
    "ROC AUC Score: 0.635 (Área bajo la curva ROC).\n",
    "\n",
    "\n",
    "Matriz de confusión\n",
    "\n",
    "[[849 (verdaderos negativos), 503 (falsos positivos)],\n",
    "\n",
    " [486 (falsos negativos), 875 (verdaderos positivos)]]\n",
    "\n",
    "\n",
    "\n",
    "## 7.Conclusiones y Recomendaciones\n",
    "\n",
    "- **7.1Conclusiones:**\n",
    "\n",
    "Mejor Modelo Seleccionado:\n",
    "\n",
    "El modelo Gradient Boosting Classifier (GBC) con parámetros óptimos mostró el mejor rendimiento, con un ROC AUC Score de 0.635, indicando una sólida capacidad para discriminar entre clases positivas y negativas.\n",
    "\n",
    "Desempeño Comparativo:\n",
    "\n",
    "El GBC superó a otros modelos, como Regresión Logística, Árbol de Decisión, Random Forest y SVM, en términos de ROC AUC Score y otras métricas de evaluación.\n",
    "\n",
    "Importancia de la Optimización de Hiperparámetros:\n",
    "\n",
    "La búsqueda de hiperparámetros óptimos contribuyó significativamente al rendimiento del GBC. La configuración encontrada (learning_rate=0.1, max_depth=2, max_features=3, n_estimators=150) equilibró la complejidad del modelo y la prevención del sobreajuste.\n",
    "\n",
    "Validación Cruzada:\n",
    "\n",
    "La validación cruzada mostró consistencia en el rendimiento del GBC en diferentes particiones de datos, con un promedio de ROC AUC Score de 0.689 y una desviación estándar baja (0.012).\n",
    "\n",
    "\n",
    "- **7.2Recomendaciones para Futuras Iteraciones:**\n",
    "\n",
    "Explorar Nuevas Características:\n",
    "\n",
    "Investigar la inclusión de nuevas características o la ingeniería de características podría mejorar aún más el rendimiento del modelo.\n",
    "\n",
    "Evaluar Modelos Ensemble:\n",
    "\n",
    "Considerar la implementación de modelos ensemble más complejos o la combinación de varios modelos para explorar sinergias y mejorar la robustez del sistema.\n",
    "\n",
    "Monitoreo Continuo:\n",
    "\n",
    "Establecer un proceso de monitoreo continuo del modelo en un entorno de producción para evaluar su rendimiento a medida que se reciben nuevos datos.\n",
    "\n",
    "Interpretación de Resultados:\n",
    "\n",
    "Profundizar en la interpretación de las características más relevantes identificadas por el GBC para obtener una comprensión más detallada de los factores que influyen en las predicciones.\n",
    "\n",
    "Considerar Datos Adicionales:\n",
    "\n",
    "Evaluar la posibilidad de incorporar datos adicionales o mejorar la calidad de los datos existentes para proporcionar al modelo una información más completa y precisa.\n",
    "\n",
    "Optimización Continua de Hiperparámetros:\n",
    "\n",
    "Realizar ajustes adicionales en la búsqueda de hiperparámetros para asegurar que el modelo esté completamente optimizado.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
